{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개요\n",
    "OpenAI의 함수 호출 기능은 AI가 생성한 텍스트를 외부 함수와 통합할 수 있도록 합니다. \\\n",
    "이를 통해 모델의 출력에 따라 코드를 실행하거나 계산을 수행하거나 데이터를 가져올 수 있습니다. \\\n",
    "함수를 정의하고 모델이 이를 호출하도록 허용함으로써 더 상호작용적이고 동적인 애플리케이션을 만들 수 있습니다.\n",
    "\n",
    "더 자세한 예제는 공식 문서를 참조하세요: [Azure OpenAI 서비스의 함수 호출](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling?tabs=non-streaming%2Cpython)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "CHAT_COMPLETIONS_MODEL = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인터넷에서 정보를 검색하는 등의 작업을 수행할 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Example function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"celsius\"):\n",
    "    \"\"\"\n",
    "    Fetch current weather using the wttr.in public API (no API key required).\n",
    "    \"\"\"\n",
    "    # wttr.in supports city names directly in the URL\n",
    "    # unit: 'm' for metric (Celsius), 'u' for US (Fahrenheit)\n",
    "    unit_flag = 'u' if unit == \"fahrenheit\" else 'm'\n",
    "    url = f\"https://wttr.in/{location}?format=j1&{unit_flag}\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=5)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        # wttr.in returns temperature in Celsius by default\n",
    "        temp_c = data[\"current_condition\"][0][\"temp_C\"]\n",
    "        temp_f = data[\"current_condition\"][0][\"temp_F\"]\n",
    "        city = location\n",
    "        temperature = temp_f if unit == \"fahrenheit\" else temp_c\n",
    "        return json.dumps({\"location\": city, \"temperature\": temperature, \"unit\": unit})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\", \"error\": str(e)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 질문을 해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울 마포구의 현재 온도는 15도입니다.\n"
     ]
    }
   ],
   "source": [
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\":\"system\", \"content\":\"\"\"귀하는 사용자가 날씨에 대한 정보를 얻을 수 있도록 설계된 AI 어시스턴트입니다. \n",
    "                 사용자가 날씨에 대한 정보를 요청하면 'get_current_weather'라는 도구 함수를 사용해야 합니다. \n",
    "                 제공된 함수만 사용하세요.\n",
    "                 함수에 어떤 값을 입력할지 함부로 추측하지 마세요. \n",
    "                 사용자 요청이 모호한 경우 설명을 요청하세요.\n",
    "                 인수의 형식은 '/*'를 포함해서는 안 되며, 속성 이름이 큰따옴표로 묶인 유효한 JSON 문자열이어야 합니다.\"\"\"},\n",
    "                 {\"role\": \"user\", \"content\": \"서울 마포구의 날씨는 어떤가요?\"}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=CHAT_COMPLETIONS_MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice = {\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\"}}\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    \n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            # Sometimes the name is classified mistakenly as python\n",
    "            if function_name == \"python\":\n",
    "                function_name = \"get_current_weather\"\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=CHAT_COMPLETIONS_MODEL,\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    "    \n",
    "\n",
    "\n",
    "print(run_conversation().choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 탐색할 사용 사례\n",
    "1. **동적 계산**  \\\n",
    "사용자 입력에 따라 실시간으로 계산을 수행합니다.\n",
    "\n",
    "2. **데이터 가져오기** \\\n",
    "모델의 출력에 따라 외부 API에서 데이터를 가져옵니다.\n",
    "\n",
    "3. **상호작용 애플리케이션** \\\n",
    "AI와 백엔드 함수를 통합하여 더 상호작용적이고 동적인 애플리케이션을 만듭니다.\n",
    "\n",
    "#### 모범 사례\n",
    "1. **명확한 프롬프트** \\\n",
    "모델로부터 정확한 응답을 얻기 위해 프롬프트를 명확하고 구체적으로 작성하세요.\n",
    "\n",
    "2. **견고한 파싱** \\\n",
    "모델 출력의 다양한 형식을 처리할 수 있도록 견고한 파싱 로직을 구현하세요.\n",
    "\n",
    "3. **오류 처리** \\\n",
    "예상치 못한 출력이나 함수 호출 실패를 관리하기 위해 오류 처리를 포함하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ai-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
